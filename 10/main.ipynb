{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. hét / Prológus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mai órán a következőkről lesz szó:\n",
    "- Idősorok elemzése 1D-CNN és RNN segítségével\n",
    "- Zajcsökkentés konvolúciós rétegekből felépített Autoencoder segítségével\n",
    "- Képszegmentáció haladó konvolúciós hálóval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. hét / I. Idősorok elemzése"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Szükséges Importok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, Conv1D, MaxPooling1D, LSTM\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Adatgyűjtés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adatok elkészítése\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. Adatok feltérképezése és preprocesszálása"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Itt nem lényeges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modell választása"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D konvolúció alapú háló\n",
    "def make_1d_convnet():\n",
    "\n",
    "# LSTM alapú háló\n",
    "def make_LSTM():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_timeseries_instances(timeseries, window_size):\n",
    "    timeseries = np.asarray(timeseries)\n",
    "\n",
    "    assert 0 < window_size < timeseries.shape[0] , \"Out of range 0 < {} < {} \".format(window_size,timeseries.shape[0])\n",
    "    \n",
    "    X = np.atleast_3d(np.array([timeseries[start:start + window_size] for start in range(0, timeseries.shape[0] - window_size)]))\n",
    "    Y = timeseries[window_size:]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_timeseries(timeseries, window_size, valid_split=0.15, test_split=0.15):\n",
    "    filter_length = 5\n",
    "    nb_filter = 4\n",
    "\n",
    "    timeseries = np.atleast_2d(timeseries)\n",
    "    if timeseries.shape[0] == 1:\n",
    "        timeseries = timeseries.T\n",
    "    nb_samples, nb_series = timeseries.shape\n",
    "    model = make_1d_convnet(window_size=window_size, filter_length=filter_length, nb_input_series=nb_series, nb_outputs=nb_series, nb_filter=nb_filter)\n",
    "    model.summary()\n",
    "\n",
    "    # Preprocessing és dataset splitting\n",
    "    X, Y = make_timeseries_instances(timeseries, window_size)\n",
    "    \n",
    "    valid_size = int(nb_samples*(1-test_split-valid_split))\n",
    "    test_size = int(nb_samples*(1-test_split))\n",
    "    X_train, Y_train = X[:valid_size], Y[:valid_size]\n",
    "    X_valid, Y_valid = X[valid_size:test_size], Y[valid_size:test_size]\n",
    "    X_test, Y_test   = X[test_size:], Y[test_size:]\n",
    "\n",
    "    # Modell illesztése\n",
    "    model.fit(X_train, Y_train, epochs=50, batch_size=16, validation_data=(X_valid, Y_valid), verbose=2)\n",
    "    \n",
    "    # Modell kiértékelése\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    return Y_test, preds  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Modell illesztése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 20\n",
    "targets, preds = evaluate_timeseries(X, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(preds, color='r', label=\"Predictions\")\n",
    "plt.plot(targets, color='g', label=\"Targets\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. hét / II. Autoencoder alapú zajcsökkentés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Szükséges Importok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Adatgyűjtés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tanítóadatok\n",
    "(x_train, _) ,(x_test, _) = \n",
    "\n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# Dataset splitting\n",
    "\n",
    "# Data normalizing\n",
    "\n",
    "print(x_train.shape, x_valid.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3. Adatfeltérképezés és data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zaj hozzáadása\n",
    "\n",
    "# Klippelés 0 és 1 közé\n",
    "\n",
    "# Vizualizáció\n",
    "n = 8\n",
    "plt.figure(figsize=(16, 4))\n",
    "for i in range(n):\n",
    "  # eredeti\n",
    "  ax = plt.subplot(1, n, i + 1)\n",
    "  ax.set_title('zajos')\n",
    "  plt.imshow(x_test_noisy[i].reshape(28,28))\n",
    "  plt.gray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modell választás"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = \n",
    "\n",
    "autoencoder.summary()\n",
    "\n",
    "autoencoder.compile(optimizer = 'adam', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Modell illesztés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "               epochs = 10,\n",
    "               batch_size = 128,\n",
    "               shuffle = True,\n",
    "               validation_data = (x_valid_noisy, x_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(x_test_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Kiértékelés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8\n",
    "plt.figure(figsize=(16, 4))\n",
    "for i in range(n):\n",
    "  # eredeti\n",
    "  ax = plt.subplot(3, n, i + 1)\n",
    "  ax.set_title('eredeti')\n",
    "  plt.imshow(x_test[i].reshape(28,28))\n",
    "  plt.gray()\n",
    "\n",
    "  # zajos\n",
    "  ax = plt.subplot(3, n, i + 1 + n)\n",
    "  ax.set_title('eredeti')\n",
    "  plt.imshow(x_test_noisy[i].reshape(28,28))\n",
    "  plt.gray()\n",
    "\n",
    "  # visszaállított\n",
    "  ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
    "  ax.set_title('visszaállított')\n",
    "  plt.imshow(decoded_imgs[i].reshape(28,28))\n",
    "  plt.gray()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Modell finomítása"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_factor = 0.4\n",
    "x_test_noisy = x_test + noise_factor * np.random.lognormal(0, 1, size=x_test.shape)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0, 1)\n",
    "\n",
    "decoded_imgs = autoencoder.predict(x_test_noisy)\n",
    "\n",
    "# eredeti, zajos és visszaállított képek kirajzolása\n",
    "n = 8\n",
    "plt.figure(figsize=(16, 4))\n",
    "for i in range(n):\n",
    "  # eredeti\n",
    "  ax = plt.subplot(3, n, i + 1)\n",
    "  ax.set_title('eredeti')\n",
    "  plt.imshow(x_test[i].reshape(28,28))\n",
    "  plt.gray()\n",
    "\n",
    "  # zajos\n",
    "  ax = plt.subplot(3, n, i + 1 + n)\n",
    "  ax.set_title('eredeti')\n",
    "  plt.imshow(x_test_noisy[i].reshape(28,28))\n",
    "  plt.gray()\n",
    "\n",
    "  # visszaállított\n",
    "  ax = plt.subplot(3, n, i + 1 + 2 * n)\n",
    "  ax.set_title('visszaállított')\n",
    "  plt.imshow(decoded_imgs[i].reshape(28,28))\n",
    "  plt.gray()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. hét / III. Képszegmentáció haladó konvolúciós háló segítségével"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Szükséges könyvtárak\n",
    "1. **TensorFlow: Datasets** - Olyan könyvtár, amelyben több, előre összeállított és feldolgozott adatbázis található\n",
    "2. **TensorFlow: Examples** - TensorFlow oktatóanyagok és adathalmazok tárolására létrehozott könyvtár\n",
    "3. **Pydot** - Neurális hálók vizaulizációjához szükséges könyvtár"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow-datasets\n",
    "%pip install tensorflow-examples\n",
    "%pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -q git+https://github.com/tensorflow/examples.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Szükséges importok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning keretrendszer\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Adathalmaz\n",
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "\n",
    "# Megjelenítés\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Adatgyűjtés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Adatfeltérképezés + 3. Adat előkészítés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizuális adatot noramlizáljuk 0 és 1 közé\n",
    "def normalize(input_image, input_mask):\n",
    "\n",
    "# Az adatok betöltése\n",
    "def load_image(datapoint):\n",
    "  # Érdemes átskálázni a bemeneti kép méretét\n",
    "\n",
    "  # Azért, hogy ne 'híguljon' fel az adat, nearest_neighbor algoritmust használunk\n",
    "\n",
    "  # A betöltés végén a képet normalizáljuk\n",
    "\n",
    "  # Visszatérünk a preprocesszált képekkel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Betöltjük az adatot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentáció\n",
    "class Augment(tf.keras.layers.Layer):\n",
    "  def __init__(self, seed=42):\n",
    "    super().__init__()\n",
    "    # Ha ugyanazzal a random seeddel dolgozunk, akkor ugyanazok fognak megfordulni\n",
    "    \n",
    "  def call(self, inputs, labels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Előkészítés a tanításhoz\n",
    "TRAIN_LENGTH = info.splits['train'].num_examples\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 1000\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
    "\n",
    "train_batches = (\n",
    "    train_images\n",
    "    .cache()\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .repeat()\n",
    "    .map(Augment())\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "\n",
    "test_batches = test_images.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Megjelenítés\n",
    "def display(display_list):\n",
    "  plt.figure(figsize=(15, 15))\n",
    "\n",
    "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "  for i in range(len(display_list)):\n",
    "    plt.subplot(1, len(display_list), i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
    "    plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "for images, masks in train_batches.take(1):\n",
    "  sample_image, sample_mask = images[0], masks[0]\n",
    "  display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modellválasztás"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"unet.jpg\"](unet.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\n",
    "\n",
    "# \"Legózás\"\n",
    "layer_names = [\n",
    "    'block_1_expand_relu',   # 64x64\n",
    "    'block_3_expand_relu',   # 32x32\n",
    "    'block_6_expand_relu',   # 16x16\n",
    "    'block_13_expand_relu',  # 8x8\n",
    "    'block_16_project',      # 4x4\n",
    "]\n",
    "base_model_outputs = [base_model.get_layer(name).output for name in layer_names]\n",
    "\n",
    "# Contracting (Feature Extractor) path létrehozása\n",
    "down_stack = tf.keras.Model(inputs=base_model.input, outputs=base_model_outputs)\n",
    "\n",
    "down_stack.trainable = False\n",
    "\n",
    "# Expansive path létrehozása\n",
    "up_stack = [\n",
    "    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
    "    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
    "    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
    "    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(output_channels:int):\n",
    "  inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n",
    "\n",
    "  # Downsampling\n",
    "  skips = down_stack(inputs)\n",
    "  x = skips[-1]\n",
    "  skips = reversed(skips[:-1])\n",
    "\n",
    "  # Upsampling\n",
    "  for up, skip in zip(up_stack, skips):\n",
    "    x = up(x)\n",
    "    concat = tf.keras.layers.Concatenate()\n",
    "    x = concat([x, skip])\n",
    "\n",
    "  # Utolsó réteg\n",
    "  last = tf.keras.layers.Conv2DTranspose(\n",
    "      filters=output_channels, kernel_size=3, strides=2,\n",
    "      padding='same')  #64x64 -> 128x128\n",
    "\n",
    "  x = last(x)\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CLASSES = 3\n",
    "\n",
    "model = unet_model(output_channels=OUTPUT_CLASSES)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "  pred_mask = tf.math.argmax(pred_mask, axis=-1)\n",
    "  pred_mask = pred_mask[..., tf.newaxis]\n",
    "  return pred_mask[0]\n",
    "\n",
    "def show_predictions(dataset=None, num=1):\n",
    "  if dataset:\n",
    "    for image, mask in dataset.take(num):\n",
    "      pred_mask = model.predict(image)\n",
    "      display([image[0], mask[0], create_mask(pred_mask)])\n",
    "  else:\n",
    "    display([sample_image, sample_mask,\n",
    "             create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    clear_output(wait=True)\n",
    "    show_predictions()\n",
    "    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Modell illesztése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 40\n",
    "VAL_SUBSPLITS = 5\n",
    "VALIDATION_STEPS = info.splits['test'].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n",
    "\n",
    "model_history = model.fit(train_batches,\n",
    "                           epochs=EPOCHS,\n",
    "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                          validation_steps=VALIDATION_STEPS,\n",
    "                          validation_data=test_batches,\n",
    "                          callbacks=[DisplayCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Modell kiértékelése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(model_history.epoch, loss, 'r', label='Training loss')\n",
    "plt.plot(model_history.epoch, val_loss, 'bo', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(test_batches, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
